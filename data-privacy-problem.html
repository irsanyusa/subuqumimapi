<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="EchoVib"><meta property="og:type" content="article"><meta name=robots content="index,follow,noarchive"><meta property="og:image" content="//img/home-bg-jeep.jpg"><meta property="twitter:image" content="//img/home-bg-jeep.jpg"><meta name=title content="The Problem With Too Much Data Privacy"><meta property="og:title" content="The Problem With Too Much Data Privacy"><meta property="twitter:title" content="The Problem With Too Much Data Privacy"><meta name=description content="Privacy has long dominated our social and legal debates about technology. The Federal Trade Commission and other central regulators aim to strengthen protections against the collection of personal data. Data minimization is the default set in Europe by the GDPR and a new bill before U.S. Congress, The American Data Privacy and Protection Act, similarly"><meta property="og:description" content="Privacy has long dominated our social and legal debates about technology. The Federal Trade Commission and other central regulators aim to strengthen protections against the collection of personal data. Data minimization is the default set in Europe by the GDPR and a new bill before U.S. Congress, The American Data Privacy and Protection Act, similarly"><meta property="twitter:description" content="Privacy has long dominated our social and legal debates about technology. The Federal Trade Commission and other central regulators aim to strengthen protections against the collection of personal data. Data minimization is the default set in Europe by the GDPR and a new bill before U.S. Congress, The American Data Privacy and Protection Act, similarly"><meta property="twitter:card" content="summary"><meta name=keyword content><link rel="shortcut icon" href=./img/favicon.ico><title>The Problem With Too Much Data Privacy |</title><link rel=canonical href=./data-privacy-problem.html><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/bootstrap.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cleanwhite/css/zanshang.css><link href=https://cdn.jsdelivr.net/gh/FortAwesome/Font-Awesome@5.15.1/css/all.css rel=stylesheet type=text/css><script src=https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/bootstrap.min.js></script>
<script src=https://assets.cdnweb.info/hugo/cleanwhite/js/hux-blog.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=./>EchoVib</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=./categories/blog>blog</a></li><li><a href=./sitemap.xml>Sitemap</a></li><li><a href=./index.xml>RSS</a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/home-bg-jeep.jpg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags></div><h1>The Problem With Too Much Data Privacy</h1><h2 class=subheading></h2><span class=meta>Posted by
Martina Birk
on
Sunday, June 23, 2024</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><img src=https://cdn.statically.io/img/api.time.com/wp-content/uploads/2022/10/Privacys-Priveledge-2022.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><span class="leading-7 float-left border-t-2 border-l-2 border-solid border-time-red text-5xl py-2 pr-0.5 pl-[0.3125rem] my-0.5 mr-2.5 font-zilla-slab">P</span>rivacy has long dominated our social and legal debates about technology. The <a href=# rel=noopener>Federal Trade Commission and other central regulators</a> aim to strengthen protections against the collection of personal data. <a href=# rel=noopener>Data minimization</a> is the default set in Europe by <a href=# rel=noopener>the GDPR</a> and a new bill before U.S. Congress, <a href=# rel=noopener>The American Data Privacy and Protection Act</a>, similarly seeks to further privacy’s primacy.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Privacy is important when it protects people against harmful surveillance and public disclosure of personal information. But privacy is just one of our democratic society’s many values, and prohibiting safe and equitable data collection can conflict with other equally valuable social goals. While we have always faced difficult choices between competing values—safety, health, access, freedom of expression and equality—advances in technology make it increasingly possible for data to be <a href=# rel=noopener>anonymized and secured</a> to balance individual interests with the public good. Privileging privacy, instead of openly acknowledging the need to balance privacy with fuller and representative data collection, obscures the many ways in which data is a public good. Too much privacy—just like too little privacy—can undermine the ways we can use information for progressive change.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">We rightfully fear surveillance when it is designed to use our personal information in harmful ways. Yet a default assumption that data collection is harmful is simply misguided. We should focus on regulating misuse rather than banning collection. Take for example perhaps the most controversial technologies that privacy advocates avidly seek to ban: facial recognition. 20 cities and counties around the U.S. have passed bans on government facial recognition. In 2019, California enacted a <a href=# rel=noopener>three-year moratorium</a> on the use of facial recognition technology in police body cameras. The two central concerns about facial recognition technology are its deficiencies in recognizing the faces of minority groups—leading, for example, to false positive searches and arrests—and its increase in population surveillance more generally. But the <a href=# rel=noopener>contemporary proposals of unnuanced bans</a> on the technology will stall improvements to its accuracy and hinder its safe integration, to the detriment of vulnerable populations.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">These outright bans ignore that surveillance cameras can help protect victims of domestic violence against abuser trespassing, <a href=# rel=noopener>help women create</a> safety networks when traveling on their own, and reduce instances of abuse of power by law enforcement. Facial recognition is increasingly <a href=# rel=noopener>aiding the fight against human trafficking and locating</a> missing people—and particularly missing children—when the technology is paired with AI that creates maturation images to bridge the missing years. There are also many beneficial uses of facial recognition for the disability community, such <a href=# rel=noopener>as assisting people</a> with impaired vision and <a href=# rel=noopener>supporting the diagnosis</a> of rare genetic disorders. While class action and ACLU lawsuits and reform proposals <a href=# rel=noopener>stack up,</a> we need balanced policies that allow facial recognition under safe conditions and restrictions.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">We also need to recognize that privacy can conflict with better, more accurate, and less biased, automation. In the contemporary <a href=# rel=noopener>techlash</a>, in which algorithms are condemned as presenting high risks of bias and exclusion, the tension between protecting personal data and the robustness of datasets must be acknowledged. For an algorithm to become more accurate and less biased, it needs data that is demographically reflective. Take health and medicine for example. Historically, clinical trials and health-data collection have privileged male and white patients. The irony of privacy regulation as a solution to exclusion and exploitation is that it fails to address the source of much bias: partial and skewed data collection. Advances in <a href=# rel=noopener>synthetic data technology</a>, which allows systems to artificially generate the data that the algorithm needs to train on can help alleviate some of these tensions between data collection and data protection. Consider facial recognition again: we need more representative training data to ensure that the technology becomes equally accurate across identities. And yet, we need to be deliberate and realistic about the need for real data for public and private innovation.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px"><strong>Read More:</strong> <a href=#>Uber Drivers Say a ‘Racist’ Algorithm Is Putting Them Out of Work</a></p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">An overemphasis on privacy <a href=# rel=noopener>can hamper advances</a> in scientific research, medicine, and public health compliance. Big data collected and mined by artificial intelligence is allowing earlier and more accurate diagnosis, advanced imaging, increased access to and reduced costs of quality care, and discovery of new connections between data and disease to discover novel treatments and cures. Put simply, if we want to support medical advances, we need more data samples from diverse populations. AI advances in <a href=# rel=noopener>radiology have resulted</a> not only in better imaging but also in reduced radiation doses and faster, safer, and more cost-effective care. The patients who stand to gain the most are those who have less access to human medical experts.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">In its natural state—to paraphrase the tech activist slogan “Information wants to be free” (and channeling the title of my own book <a href=# rel=noopener>Talent Wants to Be Free</a>)—data wants to be free. Unlike finite, tangible resources like water, fuel, land or fish, data doesn’t run out because it is used. At the same time, data’s advantage stems from its scale. We can find <a href=# rel=noopener>new proteins</a> for drug development, <a href=# rel=noopener>teach speech-to-text</a> bots to understand myriad accents and dialects, and teach algorithms to screen breast mammograms or lung x-rays when we can harness the robustness of big data—millions, sometimes billions, of data points. During the COVID-19 pandemic, governments track patterns of the spread of the disease and fight against those providing false information and selling products under fraudulent claims about cures and protections. The <a href=# rel=noopener>Human Genome Project</a> is a dazzling, paradigmatic leap in our collective knowledge and health capabilities enabled by massive data collection. But there is much more health information that needs to be collected, and privileging privacy may be <a href=# rel=noopener>bad for your health</a>.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">In health care, this need for data is perhaps intuitive, but the same holds true if we want to understand—and tackle—the root causes of other societal ills: pay gaps, discriminatory hiring and promotion, and inequitable credit, lending, and bail decisions. In <a href=# rel=noopener>my research about gender and racial-pay gaps</a>, I’ve shown that more widespread information about salaries is key. Similarly, freely <a href=# rel=noopener>sharing information online</a> about our job experiences can improve workplaces, and there are initiatives concerning privacy that may <a href=# rel=noopener>inadvertently backfire and result in statistical discrimination against more vulnerable</a> populations. For example, empirical <a href=# rel=noopener>studies</a> suggest that ban-the-box privacy policies about criminal background checks for hiring may have led to increased racial discrimination in some cities.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">Privacy—and its pervasive offshoot, <a href=# rel=noopener>the NDA</a>—has also evolved to shield the powerful and rich against<a href=# rel=noopener> the public’s right to know</a>. Even now, with regard to the right to abortion, the legal debates around reproductive justice reveal<a href=#> privacy’s weakness</a>. A more positive discourse about equality, health, bodily integrity, economic rights, and <a href=# rel=noopener>self-determination</a> would move us beyond the sticky question of what is and is not included in privacy. As I recently described in <a href=# rel=noopener>a lecture about Dobbs v. Jackson Women’s Health Organization,</a> abortion rights are far more than privacy rights; they are health rights, economic rights, equality rights, dignity rights, and human rights. In most circumstances, data collection should not be prevented but safeguarded, shared, and employed to benefit all.</p><p class="self-baseline px-0 font-pt-serif text-17px leading-7 tracking-0.5px">While staunch privacy advocates emphasize tools like informed consent and opt-out methods, these policies rely on a fallacy of individual consent. Privacy scholars agree that consent forms—those ubiquitous <a href=# rel=noopener>boilerplate</a> clickwrap policies—are rarely read or negotiated. Research also reveals that most consumers are quite agnostic to privacy settings. The behavioral literature calls this the privacy paradox, revealing that in practice people are regularly willing to engage in a <a href=# rel=noopener>privacy calculus</a>, giving up privacy for perceived benefits. So privileging privacy is both over and under-inclusive: It neglects a fuller array of values and goals we must balance, but it also fails to provide meaningful assurances for individuals and communities who have an undeniable history of being oppressed by the state and privileged elite. The dominance of privacy policy can distort nuanced debates about distributional justice and human rights, as we continue to build our digital <a href=# rel=noopener>knowledge commons</a>. Collection of important data to tackle our toughest social issues is a critical mandate of democracy.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmismaKyb6%2FOpmZvamJpgXmAjp2YrZldpb%2BqwsCcsGaooqSvrbHMaA%3D%3D</p><hr><ul class=pager><li class=previous><a href=./adoption-definitive-du-projet-de-de-loi-energie-climat-lassemblee.html data-toggle=tooltip data-placement=top title="Adoption dfinitive du projet de de loi nergie-climat  l'Assemble">&larr;
Previous Post</a></li><li class=next><a href=./0-8599-1954315-00-html.html data-toggle=tooltip data-placement=top title="Q&amp;amp;A: Dame Helen Mirren, Star of The Last Station">Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=./tags/>FEATURED TAGS</a></h5><div class=tags></div></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"></ul><p class="copyright text-muted">Copyright &copy; EchoVib 2024<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function loadAsync(i,t){var n=document,s="script",e=n.createElement(s),o=n.getElementsByTagName(s)[0];e.src=i,t&&e.addEventListener("load",function(e){t(null,e)},!1),o.parentNode.insertBefore(e,o)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(''),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("https://assets.cdnweb.info/hugo/cleanwhite/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>